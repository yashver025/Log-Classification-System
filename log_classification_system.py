# -*- coding: utf-8 -*-
"""Log Classification System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hxEP1zyXolind2b_q1Sw2ISfc6bT6o6_

## **LOG CLASSIFICATION SYSTEM**
"""

import pandas as pd
df = pd.read_csv("/content/synthetic_logs.csv")
df.head(5)

df.source.unique()

"""**Searching for patterns and creating them for REGULAR EXPRESSSIONS.**"""

from sentence_transformers import SentenceTransformer
from sklearn.cluster import DBSCAN

#Sentence Transformer (SBERT) is an improved version of BERT designed to generate efficient, meaningful sentence embeddings
model = SentenceTransformer('all-MiniLM-L6-v2')

#Generate embeddings for log messages
embeddings = model.encode(df['log_message'].tolist())

embeddings[:2]

#Perform DBSCAN clustering
dbscan = DBSCAN(eps=0.2, min_samples=1, metric='cosine')
clusters = dbscan.fit_predict(embeddings)

df['cluster'] = clusters
df.head()

df[df.cluster==1]

"""**Sort cluster by number of records in it and print 5 log messages from those clusters which have more than 10 records in it.**"""

cluster_counts = df['cluster'].value_counts()
large_clusters = cluster_counts[cluster_counts > 10].index  # Fixed variable name

for cluster in large_clusters:
    print(f"Cluster {cluster}:")
    print(df[df['cluster'] == cluster]['log_message'].head(5).to_string(index=False))
    print()

"""**Applying REGEX**"""

import re
def classify_with_regex(log_message):
    regex_patterns = {
        r"User User\d+ logged (in|out).": "User Action",
        r"Backup (started|ended) at .*": "System Notification",
        r"Backup completed successfully.": "System Notification",
        r"System updated to version .*": "System Notification",
        r"File .* uploaded successfully by user .*": "System Notification",
        r"Disk cleanup completed successfully.": "System Notification",
        r"System reboot initiated by user .*": "System Notification",
        r"Account with ID .* created by .*": "User Action"
    }
    for pattern, label in regex_patterns.items():
        if re.search(pattern, log_message, re.IGNORECASE):
            return label
    return None

if __name__ == "__main__":
    print(classify_with_regex("Backup completed successfully."))
    print(classify_with_regex("Account with ID 1234 created by User1."))
    print(classify_with_regex("Hey Bro, chill ya!"))

classify_with_regex("User User1 logged in.")

"""**Create a new column "regex_label" and if it can classify the messages with patterns it will put that particular label ("System Notification", "User Action", "None") in that column**"""

df['regex_label'] = df['log_message'].apply(classify_with_regex)
df

# log_message for which there is no REGEX patterns
df[df.regex_label.isna()]

# log_message for which there are REGEX patterns
df[df.regex_label.notnull()]

#Saving the remaining rows in - df_non_regex

df_non_regex = df[df['regex_label'].isnull()].copy()
df_non_regex

"""**Now for the remaining log_message we go for BERT(Enough training Samples) or LLM(Don't have enough training Samples)**"""

#target_label which have 5 or less rows
print(df_non_regex['target_label'].value_counts()[df_non_regex['target_label'].value_counts() <= 5].index.tolist())

"""**BERT Encoding**"""

#Filtering out the columns for which we apply BERT

df_non_legacy = df_non_regex[df_non_regex.source !='LegacyCRM']
df_non_legacy.source.unique()

filtered_embeddings = model.encode(df_non_legacy['log_message'].tolist())

filtered_embeddings[:2]

"""**Applying BERT**"""

#Model

X = filtered_embeddings
y = df_non_legacy['target_label']

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))

def classify_with_bert(log_message):
    filtered_embeddings = model.encode([log_message])

#For the logs like "Hey bro, chill ya!" where the probabilities of every class is very low and the model gets confused. So, we set a threshold that iff the probability is this then only it will classify otherwise it says UNCLASSIFIED.
    probabilities = clf.predict_proba(filtered_embeddings)[0]
    if max(probabilities) < 0.5:

      return "Unclassified"

    predicted_class = clf.predict(filtered_embeddings)[0]
    return predicted_class

if __name__ == "__main__":
    logs = [
        "alpha.osapi_compute.wsgi.server - 12.10.11.1 - API returned 404 not found error",
        "GET /v2/3454/servers/detail HTTP/1.1 RCODE   404 len: 1583 time: 0.1878400",
        "System crashed due to drivers errors when restarting the server",
        "Hey bro, chill ya!",
        "Multiple login failures occurred on user 6454 account",
        "Server A790 was restarted unexpectedly during the process of data transfer"
    ]
    for log in logs:
        label = classify_with_bert(log)
        print(log, "->", label)

"""**Applying LLM**"""

!pip install langchain_groq

API_KEY = "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"
from langchain_groq import ChatGroq
from langchain.schema import HumanMessage
import re
import os



# Initialize the Groq LLM via LangChain
llm = ChatGroq(
    model_name="deepseek-r1-distill-llama-70b",  # Use any available Groq model
    temperature=0.5,
    api_key=API_KEY
)

def classify_with_llm(log_msg):
    """
    Classifies the given log message into categories:
    (1) Workflow Error, (2) Deprecation Warning, or "Unclassified" if unknown.
    """
    prompt = f"""Classify the log message into one of these categories:
    (1) Workflow Error, (2) Deprecation Warning.
    If you can't figure out a category, use "Unclassified".
    Put the category inside <category> </category> tags.
    Log message: {log_msg}"""

    # Send message to the Groq LLM using LangChain
    response = llm.invoke([HumanMessage(content=prompt)]).content

    # Extract category using regex
    match = re.search(r'<category>(.*?)<\/category>', response, flags=re.DOTALL)
    return match.group(1) if match else "Unclassified"


if __name__ == "__main__":
    print(classify_with_llm(
        "Case escalation for ticket ID 7324 failed because the assigned support agent is no longer active."))

    print(classify_with_llm(
        "The 'ReportGenerator' module will be retired in version 4.0. Please migrate to the 'AdvancedAnalyticsSuite' by Dec 2025"))

    print(classify_with_llm("System reboot initiated by user 12345."))

"""**CLASSIFICATION**"""

def classify(logs):
    labels = []
    for source, log_msg in logs:
        label = classify_log(source, log_msg)
        labels.append(label)
    return labels


def classify_log(source, log_msg):
    if source == "LegacyCRM":
        label = classify_with_llm(log_msg)
    else:
        label = classify_with_regex(log_msg)
        if not label:
            label = classify_with_bert(log_msg)
    return label

# def classify_csv(input_file):
#     import pandas as pd
#     df = pd.read_csv(input_file)

#     # Perform classification
#     df["target_label"] = classify(list(zip(df["source"], df["log_message"])))

#     # Save the modified file
#     output_file = "output.csv"
#     df.to_csv(output_file, index=False)

    return output_file

if __name__ == '__main__':
    # classify_csv("test.csv")
    logs = [
        ("ModernCRM", "IP 192.168.133.114 blocked due to potential attack"),
        ("BillingSystem", "User 12345 logged in."),
        ("AnalyticsEngine", "File data_6957.csv uploaded successfully by user User265."),
        ("AnalyticsEngine", "Backup completed successfully."),
        ("ModernHR", "GET /v2/54fadb412c4e40cdbaed9335e4c35a9e/servers/detail HTTP/1.1 RCODE  200 len: 1583 time: 0.1878400"),
        ("ModernHR", "Admin access escalation detected for user 9429"),
        ("LegacyCRM", "Case escalation for ticket ID 7324 failed because the assigned support agent is no longer active."),
        ("LegacyCRM", "Invoice generation process aborted for order ID 8910 due to invalid tax calculation module."),
        ("LegacyCRM", "The 'BulkEmailSender' feature is no longer supported. Use 'EmailCampaignManager' for improved functionality."),
        ("LegacyCRM", " The 'ReportGenerator' module will be retired in version 4.0. Please migrate to the 'AdvancedAnalyticsSuite' by Dec 2025")
    ]
    labels = classify(logs)

    for log, label in zip(logs, labels):
        print(log[0], "->", label)